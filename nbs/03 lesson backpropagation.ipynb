{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b8b235-261c-4cdb-80af-899747254ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "from fastcore.test import test_close\n",
    "torch.manual_seed(42)\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743e0e8f-94b4-46c8-af99-e3f9e5e33799",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325f4de-c8e8-4350-9b27-a93d6d760f83",
   "metadata": {},
   "source": [
    "## initialize params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f226ba4-eff4-4023-998d-4fec65baeb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "n,m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c737a1b-5eac-46d2-9582-3a19ea3dd20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90854abd-a4b1-442e-b26a-721804eb8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=torch.randn(m,nh)\n",
    "b1=torch.zeros(nh)\n",
    "w2=torch.randn(nh, 1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddab804-0e53-4770-87bc-a001c607bc84",
   "metadata": {},
   "source": [
    "## code for model's layers, loss, and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78096968-247c-4adf-9b92-e4db2c9bd1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b):\n",
    "    return x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df343ca-9e52-43f8-a4c7-89eff7de2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9261915f-3915-4e68-a10e-6dbbbdc6c66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 0., 4.,  ..., 8., 4., 8.]),\n",
       " tensor([3., 8., 6.,  ..., 5., 6., 8.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train,y_valid=map(lambda t: t.float(), (y_train,y_valid))\n",
    "y_train,y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a8a4dd-331a-4916-b883-fa7016184b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ):\n",
    "    return (output[:,0]-targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "301515ff-7d30-43d5-a476-a7a7499c2f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = inp.t() @ out.g\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c31ca8ee-6520-42d2-84dd-70afbcdb8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(xb, yb):\n",
    "    # forward\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    preds = lin(l2, w2, b2)\n",
    "    loss = mse(preds, yb)\n",
    "\n",
    "    # backpropagation\n",
    "    n=xb.shape[0]\n",
    "    '''\n",
    "    preds is shape (batch_size, num_activation_features) = (batch_size, 1), aka a column vector\n",
    "    yb shape is (batch_size) and needs to be transformed into column vector aka (batch_size, 1)\n",
    "    hence yb[:,None], in order to do elementwise subtraction\n",
    "    '''\n",
    "    preds.g = (2./n) * (preds-yb[:,None]) \n",
    "    lin_grad(l2, preds, w2, b2)\n",
    "    l1.g = (l1 > 0).float() * l2.g\n",
    "    lin_grad(xb, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d05ed5c-e163-434d-ae25-0e69420b5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae23959-6bea-4a09-a7cb-705cc87e9e48",
   "metadata": {},
   "source": [
    "## comparing gradients to pytorch computed gradients based on same (cloned) params and same (duplicated) forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13682f0-cbb6-4925-8e3c-8c5360879b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homemade_grad(t):\n",
    "    return t.g.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450bb75b-55e1-49ed-bb1d-580c3eb0cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = w1, b1, w2, b2, x_train\n",
    "my_grads = tuple(map(get_homemade_grad, tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973e6f0d-da87-4c98-9c72-3eaed1ae0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_tensor_with_grads(t):\n",
    "    return t.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13da19fc-783d-49eb-9bfe-3cc8756335d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_tensors = tuple(map(clone_tensor_with_grads, tensors))\n",
    "w1c, b1c, w2c, b2c, x_trainc = pt_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2c4194-ea05-4726-946e-de0ebc97bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_only(inp, targ):\n",
    "    l1 = lin(inp, w1c, b1c)\n",
    "    l2 = relu(l1)\n",
    "    out = lin(l2, w2c, b2c)\n",
    "    return mse(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a7c77f4-fe73-4621-8351-8fd1b6ec2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward_only(x_trainc, y_train)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9ad39bb-2ae7-4d1c-934b-7df5b8a0aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_grad,their_tensor in zip(my_grads, pt_tensors):\n",
    "    test_close(my_grad, their_tensor.grad, eps=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c036c76-6c94-4fb5-8208-d8335fed56db",
   "metadata": {},
   "source": [
    "## Refactor model into object oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eceadaf-8bc8-4d0d-9942-c34902cccb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self):\n",
    "        self.inp.g = (self.inp > 0).int() * self.out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c3daa0-85bd-4ae0-8bbf-9b75b5a8249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin():\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp @ self.w + self.b\n",
    "        return self.out\n",
    "\n",
    "    def backward(self):\n",
    "        self.w.g = self.inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "        self.inp.g = self.out.g @ self.w.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d715583b-e659-4679-aea6-a691707ebd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse():\n",
    "    def __call__(self, preds, targ):\n",
    "        self.preds = preds\n",
    "        self.diff = preds - targ[:,None]\n",
    "        self.out = (self.diff).pow(2).mean()\n",
    "        return self.out\n",
    "\n",
    "    def backward(self):\n",
    "        self.preds.g = (2. / self.diff.shape[0]) * self.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "382d0c4e-e11b-44cc-946f-6d44624b8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [\n",
    "            Lin(w1, b1),\n",
    "            Relu(),\n",
    "            Lin(w2, b2)\n",
    "        ]\n",
    "        self.loss = Mse()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        loss = self.loss(x, y)\n",
    "        return (x, loss)\n",
    "\n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ad0690b-299b-4d7a-9ea1-1d01a3085267",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)\n",
    "preds,loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55f4392b-4f5c-46ad-b2ec-44452bde03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,w2,b1,b2,x_train,y_train = tuple(map(lambda t: t.to('cuda'), (w1,w2,b1,b2,x_train,y_train,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "508daa1e-0113-41e4-9c7e-1073d0f77415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(preds, y):\n",
    "    return (preds[:,0].round() == y).half().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e17fcefd-cc9a-49fc-a790-98b841717ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw1, pb1, pw2, pb2 = w1.clone(), b1.clone(), w2.clone(), b2.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0f4eeaf-c8f3-4f7c-b28e-3a5f894a9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2= pw1, pb1, pw2, pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "043780a8-f706-4aba-9a18-b710182557d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(5253.24, device='cuda:0') tensor(0.00, device='cuda:0', dtype=torch.float16)\n",
      "1000 tensor(8.36, device='cuda:0') tensor(0.10, device='cuda:0', dtype=torch.float16)\n",
      "2000 tensor(8.36, device='cuda:0') tensor(0.10, device='cuda:0', dtype=torch.float16)\n",
      "3000 tensor(8.36, device='cuda:0') tensor(0.10, device='cuda:0', dtype=torch.float16)\n",
      "4000 tensor(8.36, device='cuda:0') tensor(0.10, device='cuda:0', dtype=torch.float16)\n",
      "5000 tensor(8.36, device='cuda:0') tensor(0.10, device='cuda:0', dtype=torch.float16)\n",
      "6000 tensor(8.36, device='cuda:0') tensor(0.10, device='cuda:0', dtype=torch.float16)\n",
      "7000 tensor(8.36, device='cuda:0') tensor(0.10, device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model(w1, b1, w2, b2)\n\u001b[0;32m----> 4\u001b[0m     preds,loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m l(x)\n\u001b[0;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (x, loss)\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mMse.__call__\u001b[0;34m(self, preds, targ)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreds \u001b[38;5;241m=\u001b[39m preds\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiff \u001b[38;5;241m=\u001b[39m preds \u001b[38;5;241m-\u001b[39m targ[:,\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.05\n",
    "for i in range(1000000):\n",
    "    model = Model(w1, b1, w2, b2)\n",
    "    preds,loss = model(x_train, y_train)\n",
    "    model.backward()\n",
    "    if i % 1000 == 0:\n",
    "        print(i, loss,acc(preds, y_train))\n",
    "    w1 -= lr * w1.g\n",
    "    b1 -= lr * b1.g\n",
    "    w2 -= lr * w2.g\n",
    "    b2 -= lr * b2.g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd89aa-c403-4a4c-ae61-261daac758d3",
   "metadata": {},
   "source": [
    "## Refactor, use forward() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53f0ae8d-68b2-46cf-8090-a62461cd75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "\n",
    "    def forward(self): \n",
    "        None\n",
    "    def backward(self):\n",
    "        # save the args in flight in __call__ to pass them again here. still need to declare them in signature,\n",
    "        # but don't need to chase down vals to pass them in again\n",
    "        self.bwd(self.out, *self.args)\n",
    "    def bwd(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa6e07e4-3f47-4844-9955-9d40df957119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Module):\n",
    "    def forward(self, inp):\n",
    "        return inp.clamp_min(0.)\n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g * (inp > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14dc8317-f381-4595-bccb-5ad5eb311c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "    def forward(self, inp):\n",
    "        return inp @ self.w + self.b\n",
    "\n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff2a9330-1d6b-4520-b6bf-320ffd6160c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse(Module):\n",
    "    def forward(self, inp, targ):\n",
    "        return (inp.squeeze() - targ).pow(2).mean()\n",
    "\n",
    "    def bwd(self, out, inp, targ):\n",
    "        inp.g = 2*(inp.squeeze() - targ).unsqueeze(-1) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b1a1f50-1bd5-440b-af02-60f2ac28f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8f72f22-cdfe-4cbb-a2cc-1ce7968285ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5537b6f9-4365-4982-938e-7c52df4b8680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.45],\n",
       "         [4.45],\n",
       "         [4.45],\n",
       "         ...,\n",
       "         [4.45],\n",
       "         [4.45],\n",
       "         [4.45]], device='cuda:0'),\n",
       " tensor(8.36, device='cuda:0'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fca3500c-3896-4447-80ba-6539f65bf211",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfaf12-dbe0-4ca0-a6e9-0cc9e149bca1",
   "metadata": {},
   "source": [
    "## autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2d378fe-8120-4bac-bbfa-5819b844f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f0c2b23-2f77-4dc6-a993-c5b6c598a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.w = torch.randn(n_in, n_out).to('cuda').requires_grad_()\n",
    "        self.b = torch.zeros(n_out).to('cuda').requires_grad_()\n",
    "    def forward(self, inp):\n",
    "        return inp@self.w + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d6572e5-3f1f-40af-af77-bd1e4f442aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [Linear(n_in, nh), nn.ReLU(), Linear(nh, n_out)]\n",
    "\n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return (x, F.mse_loss(x, targ[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6e51b4e-36a4-4538-9827-4fdc7e96526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6eb9355a-fc2f-4154-aa6a-3118a5dbde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out,loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b04fcc7-46c1-4250-975b-5845d71e59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5609a8f7-0294-40c0-8b23-41e16c21cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    25.94,     39.71,     59.51,     13.67,     59.99,    -52.92,    -95.64,      5.11,     26.07,     -4.32,\n",
       "           -67.83,   -183.01,    -26.47,    -33.72,     70.47,      2.54,    -48.64,   -118.62,     23.59,      9.02,\n",
       "          -245.84,    -35.43,    -25.58,     24.89,    -14.35,     -4.79,    -40.82,    -68.20,     16.47,    122.15,\n",
       "          -179.85,    -30.03,    -24.63,    -36.48,    214.56,     35.95,     65.49,     16.53,     15.27,    -74.02,\n",
       "           -67.38,    -28.08,     11.56,    -83.02,     23.20,     -7.73,     24.34,    -46.75,     99.27,   -162.95,\n",
       "           -43.80,     69.14,      9.87,   -110.22,    -13.57,     -2.81,     -5.78,    -30.22,    -19.45,     54.48,\n",
       "            40.27,     62.32,     -7.23,    -16.30,    125.21,      8.19,     68.10,     -1.61,    -28.98,     -2.74,\n",
       "            32.40,    -23.22,     51.09,     45.71,    -45.75,     -5.73,     11.74,    -11.81,      1.66,    208.56,\n",
       "            83.04,     63.33,      4.97,    -36.27,    -53.70,    -49.84,      0.78,    -65.86,    -56.87,      0.17,\n",
       "          -175.67,    -14.91,    125.07,     56.61,     21.87,     16.15,    -90.40,     -5.95,     59.10,    -20.86,\n",
       "           -19.37,     94.38,      8.10,     -1.54,    -23.21,    115.97,     78.51,     -7.00,    -99.64,     14.83,\n",
       "            40.56,     50.95,      7.79,    -69.28,     82.23,     47.40,     13.32,      8.61,     18.67,    -62.98,\n",
       "           -37.34,      2.72,    -10.32,    148.81,      3.24,     24.78,      1.33,    -10.08,    -11.16,    -22.59,\n",
       "             1.39,     69.07,      6.53,     73.69,    101.21,    -91.44,    126.51,     90.67,     -3.22,    -45.49,\n",
       "            81.38,    176.24,   -126.43,     52.11,    -24.02,     24.90,    108.35,     -0.64,      3.57,     40.83,\n",
       "            47.19,    -27.01,    140.70,    -16.74,     90.41,      0.71,     36.54,      5.13,    105.14,     92.44,\n",
       "            48.78,   -182.66,    210.70,   -148.74,    -74.79,    -32.68,    -73.54,     50.15,    -11.92,    -29.52,\n",
       "            70.77,     80.36,    -38.86,    -65.11,     82.44,    -27.19,      3.22,      2.87,     39.96,    -43.29,\n",
       "           271.36,     -0.38,    -31.25,     54.29,    -13.34,   -119.15,     -9.83,    -30.38,     -7.84,     38.54,\n",
       "            82.14,    -31.84,    101.49,     65.94,      5.60,     88.53,    -29.37,    -62.83,     -9.65,   -189.53],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].b.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
