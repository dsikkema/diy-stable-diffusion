{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2731d393-cffe-4f7c-bc0d-a96b5e64a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d16bca-6e37-43c8-82a8-cfcc621514a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import math, torch, matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from diy_stable_diffusion.conv import *\n",
    "\n",
    "from fastprogress import progress_bar,master_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c10dee-f87d-46af-a25a-2e0f5dc5d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn, tensor\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "from diy_stable_diffusion.datasets import *\n",
    "import logging\n",
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1d7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a947f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "306fa6bf-fbba-462d-b1fd-c025fd05106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93527d7177b54096b9396fab9dedd135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed838b7f0494a22ae93cc1313f8332f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset fashion_mnist/fashion_mnist (download: 29.45 MiB, generated: 34.84 MiB, post-processed: Unknown size, total: 64.29 MiB) to /root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9907138f2a07438192e079276a53c900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fc7d91adb144669e071c718d55f6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c9c05d97d84ad59b6097041d70ea9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/29.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d6bd7b9520417d877f3b7be74918d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d8d37bdc5140af99a3d9a129a040aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16719be1f9fb400fbcd0379ff5dcad09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset fashion_mnist downloaded and prepared to /root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b65b066e1d4f19b831238aff197950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetdict = load_dataset(\"fashion_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc24312-dbdd-4420-bef4-739ef33e7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b):\n",
    "    b['image'] = [torch.flatten(TF.to_tensor(i)) for i in b['image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa31485-1c81-4541-a2be-59fb555cc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "datasetdict = datasetdict.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(datasetdict, bs, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc586395-cf60-44d8-9cd1-5d47926d53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class CancelFitException(Exception):\n",
    "    pass\n",
    "class CancelBatchException(Exception):\n",
    "    pass\n",
    "class CancelEpochException(Exception):\n",
    "    pass\n",
    "\n",
    "class Callback:\n",
    "    order = 0\n",
    "    _fwd = 'model','opt', 'batch', 'epoch'\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        if name in self._fwd:\n",
    "            return getattr(self.learn, name)\n",
    "        super().__getattr__(self, name)\n",
    "    \n",
    "    def __setattr__(self, name, val):\n",
    "        if name in self._fwd:\n",
    "            warn(f'setting {name} in callback, did you mean to set it on learner? Attribute accessible by proxy on the callback.')\n",
    "        super().__setattr__(name, val)\n",
    "    \n",
    "    @property\n",
    "    def training(self):\n",
    "        return self.model.training\n",
    "    \n",
    "\n",
    "def run_cbs(cbs, methodname, learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, methodname, None)\n",
    "        if method is not None:\n",
    "            method(learn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73ebc592-52de-45be-a8f3-7d2a1d832fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SingleBatchCB(Callback):\n",
    "    order = 1\n",
    "    def after_batch(self, learn):\n",
    "        raise CancelFitException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9147beb-92c3-41ba-91be-7df992a10248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.vals = []\n",
    "        self.ns = []\n",
    "        \n",
    "    def add(self, inp, targ = None, n=1):\n",
    "        self.last = self.calc(inp, targ)\n",
    "        self.vals.append(self.last)\n",
    "        self.ns.append(n)\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        ns = tensor(self.ns)\n",
    "        return (tensor(self.vals)*ns).sum() / ns.sum() # weighted mean\n",
    "\n",
    "    def calc(self, inps, targs):\n",
    "        return inps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4fb99-a08a-416f-9d79-27051410facb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "779ee8b2-db8b-46e7-8abc-f5f3ab1e5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metrics):\n",
    "    def calc(self, inps, targs):\n",
    "        return (inps == targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0ba16c9-8413-490c-bddf-7a7412555fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = Accuracy()\n",
    "acc.add(tensor([1, 1, 1]), tensor([2, 2, 2]))\n",
    "acc.add(tensor([2]), tensor([2]))\n",
    "acc.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a636f361-4ff7-4a9c-b533-c701e4f9dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torcheval.metrics import Mean,MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c81b0d68-f425-4aac-9c99-f2e329bde6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def to_cpu(x):\n",
    "    if isinstance(x, Mapping):\n",
    "        return {k:to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x, list):\n",
    "        return [to_cpu(i) for i in x]\n",
    "    if isinstance(x, tuple):\n",
    "        return tuple(to_cpu(list(x)))\n",
    "    \n",
    "    x = x.detach().cpu()\n",
    "    \n",
    "    return x.float() if x.dtype==torch.float16 else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f0920b3-3c6d-4a51-860f-296cb1cbf30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, [3, 4, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a bunch of all the rest of the stuff in the tuple packed into _\n",
    "a, b, *_ = (1, 2, 3, 4, 5)\n",
    "a, b, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01de6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "note; copy pasted, only hand-copied the exported version\n",
    "'''\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, dls, loss_func, lr, cbs, opt_func=optim.SGD): fc.store_attr()\n",
    "\n",
    "    def one_batch(self):\n",
    "        self.preds = self.model(self.batch[0])\n",
    "        self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "        if self.model.training:\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        self.model.train(train)\n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        try:\n",
    "            self.callback('before_epoch')\n",
    "            for self.iter,self.batch in enumerate(self.dl):\n",
    "                try:\n",
    "                    self.callback('before_batch')\n",
    "                    self.one_batch()\n",
    "                    self.callback('after_batch')\n",
    "                except CancelBatchException: pass\n",
    "            self.callback('after_epoch')\n",
    "        except CancelEpochException: pass\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.epochs = range(n_epochs)\n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        try:\n",
    "            self.callback('before_fit')\n",
    "            for self.epoch in self.epochs:\n",
    "                self.one_epoch(True)\n",
    "                self.one_epoch(False)\n",
    "            self.callback('after_fit')\n",
    "        except CancelFitException: pass\n",
    "\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cfe8233-c18a-48e3-8c54-4d2b9115def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MetricsCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): learn.metrics = self\n",
    "    def before_epoch(self, learn): [o.reset() for o in self.all_metrics.values()]\n",
    "\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values(): m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70de4b74-c88c-47c3-840e-5c5e4a4fb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device = def_device):\n",
    "        self.device = def_device\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'):\n",
    "            learn.model.to(self.device)\n",
    "    def before_batch(self, learn):\n",
    "        learn.batch = to_device(learn.batch, device = self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c60e7887-fcc0-4af4-8be8-4f7d3f4b2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 784\n",
    "hidden_features = 50\n",
    "def get_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features,hidden_features),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_features,10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7913e80c-8c32-4151-9adc-90fffb006639",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8b38f45-254e-4632-a143-f783dfb70381",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCB(accuracy = MulticlassAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b37c4c-c86b-4892-8e55-c6b62e1cd54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, dls, F.cross_entropy, lr=0.2, \n",
    "                cbs = [DeviceCB(), MetricsCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a615e-7e41-481d-ab04-3c0febefc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ab5ba-c00b-4358-9231-9389f4a46669",
   "metadata": {},
   "source": [
    "## Updated learner\n",
    "using decorator for callbacks, at the end of lesson nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2678cf0-57ad-4f50-8264-df176aba01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class with_cbs:\n",
    "    def __init__(self, cbname):\n",
    "        self.cbname = cbname\n",
    "    \n",
    "    def __call__(self, f):\n",
    "        def _f(other, *args, **kwargs):\n",
    "            try:\n",
    "                '''\n",
    "                here, other means the self of the method, hence, a Learner\n",
    "                instance\n",
    "                '''\n",
    "                other.callback(f'before_{self.cbname}')\n",
    "                f(other, *args, **kwargs)\n",
    "                other.callback(f'after_{self.cbname}')\n",
    "            # Note: if CancelXException doesn't exist then what? what then?\n",
    "            except globals()[f'Cancel{self.cbname.title()}Exception']:\n",
    "                pass\n",
    "            finally:\n",
    "                other.callback(f'cleanup_{self.cbname}')\n",
    "            \n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cfb6c-39c4-4a42-bdcf-0f6f0b20f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Learner():\n",
    "    def __init__(self, model, dls=(0,), loss_func = F.mse_loss, lr=0.1,\n",
    "                 cbs=None, opt_func=optim.SGD):\n",
    "        cbs = fc.L(cbs)\n",
    "        fc.store_attr()\n",
    "    \n",
    "    @with_cbs('batch')\n",
    "    def _one_batch(self):\n",
    "        self.predict()\n",
    "        self.callback('after_predict')\n",
    "        self.get_loss()\n",
    "        self.callback('after_loss')\n",
    "        if self.training:\n",
    "            self.backward()\n",
    "            self.callback('after_backward')\n",
    "            self.step()\n",
    "            self.callback('after_step')\n",
    "            self.zero_grad()\n",
    "    \n",
    "    \n",
    "    @with_cbs('epoch')\n",
    "    def _one_epoch(self):\n",
    "        for self.iter, self.batch in enumerate(self.dl):\n",
    "            self._one_batch()\n",
    "    \n",
    "    def one_epoch(self, is_training):\n",
    "        self.model.train(is_training)\n",
    "        self.dl = self.dls.train if is_training else self.dls.valid\n",
    "        self._one_epoch()\n",
    "        \n",
    "    @with_cbs('fit')\n",
    "    def _fit(self, do_train, do_validate):\n",
    "        # have to iterate over an \"epochs\" range, because\n",
    "        # this has to be extensible in arbitrary, unintuitive, unexpected ways\n",
    "        for self.epoch in self.epoch_range:\n",
    "            if do_train:\n",
    "                self.one_epoch(True)\n",
    "            if do_validate:\n",
    "                with torch.no_grad():\n",
    "                    self.one_epoch(False)\n",
    "                    \n",
    "    def fit(self, n_epochs=1, do_train=True, do_validate=True, cbs=None, lr=None):\n",
    "        cbs=fc.L(cbs)\n",
    "        for cb in cbs:\n",
    "            # removed at the finally\n",
    "            self.cbs.append(cb) \n",
    "        try:\n",
    "            self.n_epochs = n_epochs\n",
    "            self.epoch_range = range(n_epochs)\n",
    "            if lr is None:\n",
    "                lr = self.lr\n",
    "\n",
    "            # I guess just nothing works if this isn't provided in __init__\n",
    "            if self.opt_func is not None:\n",
    "                # another permanent change to learner state\n",
    "                self.opt = self.opt_func(self.model.parameters(), lr)\n",
    "            self._fit(do_train, do_validate)\n",
    "        finally:\n",
    "            for cb in cbs:\n",
    "                self.cbs.remove(cb)\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict', 'get_loss', 'backward', 'step', 'zero_grad'):\n",
    "            return partial(self.callback, name)\n",
    "        else:\n",
    "            raise AttributeError(name)\n",
    "            \n",
    "    def callback(self, name):\n",
    "        run_cbs(self.cbs, name, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self):\n",
    "        return self.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af67a6-21de-4a47-8d14-c7171d491a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainCB(Callback):\n",
    "    def __init__(self, n_inp=1):\n",
    "        self.n_inp = n_inp\n",
    "    \n",
    "    def predict(self, learn):\n",
    "        learn.preds = learn.model(*learn.batch[:self.n_inp])\n",
    "        \n",
    "    def get_loss(self, learn):\n",
    "        learn.loss = learn.loss_func(learn.preds, *learn.batch[self.n_inp:])\n",
    "    \n",
    "    def backward(self, learn):\n",
    "        learn.loss.backward()\n",
    "    \n",
    "    def step(self, learn):\n",
    "        learn.opt.step()\n",
    "    def zero_grad(self, learn):\n",
    "        learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692fbeb-aa47-410c-b981-dad086872d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =master_bar(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c158f48-68a0-4d11-876f-c5ef526e255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    z=[i for i in range(int(1e7))]\n",
    "    x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693206a-4932-41e8-a46a-99653d6c64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m={'a': 1, 'z': 99}\n",
    "list(m),m.keys(),list(m.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ed51f-fe53-47d9-a3f5-faa69939ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressCB(Callback):\n",
    "    order = MetricsCB.order + 1\n",
    "    def __init__(self, plot=False):\n",
    "        self.plot = plot\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        learn.epoch_range = self.mbar = master_bar(learn.epoch_range)\n",
    "        self.first = True\n",
    "        \n",
    "        # this just waits for a bug where some different thing is called\n",
    "        # metrics. This whole code base is an exercise in making sure\n",
    "        # every possible bit in the computer's RAM is tightly coupled\n",
    "        # with every other bit.\n",
    "        if hasattr(learn, 'metrics'):\n",
    "            learn.metrics._log = self._log\n",
    "        \n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def _log(self, logdict):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(logdict.keys()), table=True)\n",
    "            self.first = False\n",
    "        \n",
    "        self.mbar.write(list(logdict.values()), table=True)\n",
    "        \n",
    "    def before_epoch(self, learn):\n",
    "        learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        # Assumes dl field of learner has been mutated by this class, turned\n",
    "        # into a progress bar type. Sure do hope no other callbacks make\n",
    "        # conflicting assumptions about learn.dl, learn.epoch_range, etc\n",
    "        learn.dl.comment = f'{learn.loss:.3f}'\n",
    "        \n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.losses.append(learn.loss.item())\n",
    "            if self.val_losses:\n",
    "                self.mbar.update_graph(\n",
    "                    [\n",
    "                        [fc.L.range(self.losses), self.losses],\n",
    "                        [\n",
    "                            fc.L.range(learn.epoch).map(lambda x: (x+1)*len(learn.dls.train)),\n",
    "                            self.val_losses\n",
    "                        ]\n",
    "                    ])\n",
    "    \n",
    "    def after_epoch(self, learn):\n",
    "        if not learn.training:\n",
    "            if self.plot and hasattr(learn, 'metrics'):\n",
    "                self.val_losses.append(learn.metrics.all_metrics['loss'].compute())\n",
    "                self.mbar.update_graph(\n",
    "                    [[fc.L.range(self.losses), self.losses],\n",
    "                     [\n",
    "                         fc.L.range(learn.epoch+1).map(lambda x: (x+1)*len(learn.dls.train)),\n",
    "                         self.val_losses\n",
    "                     ]\n",
    "                    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b63e2-c784-413d-8e5d-f0070da3d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()\n",
    "metrics=MetricsCB(accuracy=MulticlassAccuracy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601f602-475d-4daf-8862-0e981279d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs=[TrainCB(), DeviceCB(), metrics, ProgressCB(plot=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360510c-4066-4807-887a-ac2658e1c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, dls, F.cross_entropy, lr=0.2, cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e15917-d354-4703-8934-3ca3e6da08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainLearner(Learner):\n",
    "    def predict(self): self.preds = self.model(self.batch[0])\n",
    "    def get_loss(self): self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "    def backward(self): self.loss.backward()\n",
    "    def step(self): self.opt.step()\n",
    "    def zero_grad(self): self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68148d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MomentumLearner(TrainLearner):\n",
    "    def __init__(self, model, dls, loss_func, lr=None, cbs=None, opt_func=optim.SGD, mom=0.85):\n",
    "        self.mom = mom\n",
    "        super().__init__(model, dls, loss_func, lr, cbs, opt_func)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.model.parameters(): p.grad *= self.mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac47756-4082-419c-83d5-61fc92710591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainMomentumCB(TrainCB):\n",
    "    \n",
    "    def __init__(self, mom):\n",
    "        self.mom = mom\n",
    "        super().__init__()\n",
    "    \n",
    "    def zero_grad(self, learn):\n",
    "        with torch.no_grad():\n",
    "            for p in learn.model.parameters():\n",
    "                p.grad *= self.mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a6851-d044-4fcc-9a5c-604c726bd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "cbs = [TrainMomentumCB(0.85), DeviceCB(), metrics, ProgressCB(plot=True)]\n",
    "learn = Learner(get_model(), dls, F.cross_entropy, lr=0.25, cbs=cbs)\n",
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581aaa4a-525a-41e9-ae90-aab7ff1335e8",
   "metadata": {},
   "source": [
    "## LR finder callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce33b2-e116-4044-a045-020aaf78eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRFinderCB(Callback):\n",
    "    def __init__(self, lr_mult = 1.3):\n",
    "        self.lr_mult = lr_mult\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        self.lrs, self.losses = [], []\n",
    "        self.min = math.inf\n",
    "        \n",
    "    def after_batch(self, learn):\n",
    "        if not learn.training:\n",
    "            raise CancelEpochException()\n",
    "        # I mean, just, you know, it's fine.\n",
    "        self.lrs.append(learn.opt.param_groups[0]['lr'])\n",
    "        loss = to_cpu(learn.loss)\n",
    "        self.losses.append(loss)\n",
    "        \n",
    "        if loss < self.min:\n",
    "            self.min = loss\n",
    "        if loss > self.min * 3:\n",
    "            raise CancelFitException()\n",
    "        \n",
    "        for g in learn.opt.param_groups:\n",
    "            # ?????? deep learning I mean deep magic more like it???\n",
    "            g['lr'] *= self.lr_mult\n",
    "    def after_fit(self, learn):\n",
    "        plt.plot(self.lrs, self.losses)\n",
    "        plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5e2bd-8776-4083-a31f-37ffe91436c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind = LRFinderCB()\n",
    "cbs = [lrfind, TrainMomentumCB(0.85), DeviceCB(), metrics, ProgressCB(plot=True)]\n",
    "learn = Learner(get_model(), dls, F.cross_entropy, lr=1e-4, cbs=cbs)\n",
    "learn.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e3e9a-0e86-4375-acab-d372e05f7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lrfind.lrs, lrfind.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd1f22-d98f-4d5f-bee4-50610150955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lrfind.lrs, lrfind.losses)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39370abd-7dcc-430c-9759-416272c6312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bac6f4-4bc1-4e8e-8f97-5502340af30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LRFinderCB(Callback):\n",
    "    def __init__(self, gamma=1.3, max_mult=3):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        # sched.step will mutate lr inside the optimizer according to gamma\n",
    "        # exponent\n",
    "        self.sched = ExponentialLR(learn.opt, self.gamma)\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        self.min = math.inf\n",
    "        \n",
    "    def after_batch(self, learn):\n",
    "        if not learn.training:\n",
    "            raise CancelEpochException()\n",
    "        \n",
    "        self.lrs.append(learn.opt.param_groups[0]['lr']) # Note, I changed this, is it broken?\n",
    "        loss = to_cpu(learn.loss)\n",
    "        self.losses.append(loss)\n",
    "        \n",
    "        if loss < self.min:\n",
    "            self.min = loss\n",
    "        if math.isnan(loss) or (loss > self.min * self.max_mult):\n",
    "            raise CancelFitException()\n",
    "        \n",
    "        self.sched.step()\n",
    "        \n",
    "    # new callback type \"cleanup\" will not be cancelled by\n",
    "    # cancel fit exception, but after_fit will\n",
    "    def cleanup_fit(self, learn):\n",
    "        plt.plot(self.lrs, self.losses)\n",
    "        plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf93bd-3e3a-4e98-b902-1d3487bc7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = MomentumLearner(get_model(), dls, F.cross_entropy,\n",
    "                        lr=1e-5, cbs=[DeviceCB()])\n",
    "learn.fit(3, cbs=[LRFinderCB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35032f06-f829-4633-bd3d-9700269d8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "@fc.patch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff226c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@fc.patch\n",
    "def lr_find(self:Learner, gamma=1.3, max_mult=3, start_lr=1e-5, max_epochs=10):\n",
    "    self.fit(max_epochs, lr=start_lr, cbs=LRFinderCB(gamma=gamma, max_mult=max_mult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c072c6f-9439-46de-9d88-51ce9ca5830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MomentumLearner(get_model(), dls, F.cross_entropy, cbs=[DeviceCB()]).lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d74526bd-0602-4d8f-a7b7-2a6d577af1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
