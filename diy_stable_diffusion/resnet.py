# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/13 copy resnets.ipynb.

# %% auto 0
__all__ = ['act_genrelu', 'ResBlock']

# %% ../nbs/13 copy resnets.ipynb 1
import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt
import fastcore.all as fc
from collections.abc import Mapping
from pathlib import Path
from operator import attrgetter,itemgetter
from functools import partial
from copy import copy
from contextlib import contextmanager

import torchvision.transforms.functional as TF,torch.nn.functional as F
from torch import tensor,nn,optim
from torch.utils.data import DataLoader,default_collate
from torch.nn import init
from torch.optim import lr_scheduler
from torcheval.metrics import MulticlassAccuracy
from datasets import load_dataset,load_dataset_builder

from .datasets import *
from .conv import *
from .learner import *
from .activations import *
from .init import *
from .sgd import *

# %% ../nbs/13 copy resnets.ipynb 4
act_genrelu = partial(GeneralRelu, leak=0.1, sub=0.4)

# %% ../nbs/13 copy resnets.ipynb 14
'''
Note on convolution layers that change number of channels. Each output channel has a different
kernel corresponding to each of I input layers. The results of those I convolutions are combined
(for instance by adding, or averaging) to form the convolution result for that channel. Hence
the parameters shape for a conv layer with O output channels, I input channels, and K*K kernel is
(O, I, K, K).
'''

def _conv_block(in_channels, out_channels, stride, activation=act_genrelu, norm=None, ks=3):
    return nn.Sequential(
        # first conv in block: do NOT change image height/width (stride=1), DO change channel count.
        conv(in_channels, out_channels, kernel_size=ks, stride=1, activation=activation, norm=norm),
        # second cond: DO change image height/width (using stride), do NOT change channel count
        # (input and output channel count are the same)
        conv(out_channels, out_channels, kernel_size=ks, stride=stride, activation=None, norm=norm)
    )

class ResBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, ks=3, act=act_genrelu, norm=None):
        super().__init__()
        self.block = _conv_block(in_channels, out_channels, stride=stride, activation=act, norm=norm)
        
        '''
        The following two modules are relevent if either the number of channels, or the size of the
        image, respectively, are being changed. They're meant to try to preserve identity across such
        a dimensionality change. idconv applies a convolution layer to transform the channel count. 
        (Note to self, why can't we initialize the conv weights to something resembling an identity
        transformation from the getgo?). pool module can handle a stride which reduces image size
        because I don't think convolutions can increase image size, only upsampling does that. So
        pool in this case does an averaging over a number of pixels to match stride and downscales
        input appropriately.
        '''
        self.idconv = fc.noop if in_channels==out_channels else conv(in_channels, out_channels, stride=1, kernel_size=1, activation=None)
        self.pool = fc.noop if stride==1 else nn.AvgPool2d(stride, ceil_mode=True)
        self.act = act()
    
    def forward(self, x):
        # conceptually, the pool is just part of the idconv, but it's broken out this way for simplicity
        return self.act(self.block(x) + self.idconv(self.pool(x)))
